{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #matrix math \n",
    "import tensorflow as tf #machine learningt\n",
    "#import helpers\n",
    "tf.reset_default_graph() #Clears the default graph stack and resets the global default graph.\n",
    "sess = tf.InteractiveSession() #initializes a tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First critical thing to decide: vocabulary size.\n",
    "#Dynamic RNN models can be adapted to different batch sizes \n",
    "#and sequence lengths without retraining \n",
    "#(e.g. by serializing model parameters and Graph definitions via tf.train.Saver), \n",
    "#but changing vocabulary size requires retraining the model.\n",
    "# paramters\n",
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20 #character length\n",
    "\n",
    "encoder_hidden_units = 20 #num neurons\n",
    "decoder_hidden_units = encoder_hidden_units * 2 #in original paper, they used same number of neurons for both encoder\n",
    "#and decoder, but we use twice as many so decoded output is different, the target value is the original input \n",
    "#in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input placehodlers\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "#contains the lengths for each of the sequence in the batch, we will pad so all the same\n",
    "#if you don't want to pad, check out dynamic memory networks to input variable length sequences\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length') \n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#randomly initialized embedding matrrix that can fit input sequence\n",
    "#used to convert sequences to vectors (embeddings) for both encoder and decoder of the right size\n",
    "#reshaping is a thing, in TF you gotta make sure you tensors are the right shape (num dimensions)\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "#this thing could get huge in a real world application\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple\n",
    "encoder_cell = LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenates tensors along one dimension.\n",
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "#letters h and c are commonly used to denote \"output value\" and \"cell state\". \n",
    "#http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "#Those tensors represent combined internal state of the cell, and should be passed together. \n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "#TF Tuple used by LSTM Cells for state_size, zero_state, and output state.\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units) \n",
    "#we could print this, won't need\n",
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))\n",
    "decoder_lengths = encoder_inputs_length + 3\n",
    "# +2 additional steps, +1 leading <EOS> token for decoder inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually specifying since we are going to implement attention details for the decoder in a sec\n",
    "#weights\n",
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype=tf.float32)\n",
    "#bias\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create padded inputs for the decoder from the word embeddings\n",
    "\n",
    "#were telling the program to test a condition, and trigger an error if the condition is false.\n",
    "assert EOS == 1 and PAD == 0\n",
    "\n",
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "#retrieves rows of the params tensor. The behavior is similar to using indexing with arrays in numpy\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually specifying loop function through time - to get initial cell state and input to RNN\n",
    "#normally we'd just use dynamic_rnn, but lets get detailed here with raw_rnn\n",
    "\n",
    "#we define and return these values, no operations occur here\n",
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n",
    "    #end of sentence\n",
    "    initial_input = eos_step_embedded\n",
    "    #last time steps cell state\n",
    "    initial_cell_state = encoder_final_state\n",
    "    #none\n",
    "    initial_cell_output = None\n",
    "    #none\n",
    "    initial_loop_state = None  # we don't need to pass any additional information\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)\n",
    "#attention mechanism --choose which previously generated token to pass as input in the next timestep\n",
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "\n",
    "    \n",
    "    def get_next_input():\n",
    "        #dot product between previous ouput and weights, then + biases\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        #Logits simply means that the function operates on the unscaled output of \n",
    "        #earlier layers and that the relative scale to understand the units is linear. \n",
    "        #It means, in particular, the sum of the inputs may not equal 1, that the values are not probabilities \n",
    "        #(you might have an input of 5).\n",
    "        #prediction value at current time step\n",
    "        \n",
    "        #Returns the index with the largest value across axes of a tensor.\n",
    "        prediction = tf.argmax(output_logits, axis=1)\n",
    "        #embed prediction for the next input\n",
    "        next_input = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    \n",
    "    elements_finished = (time >= decoder_lengths) # this operation produces boolean tensor of [batch_size]\n",
    "                                                  # defining if corresponding sequence has ended\n",
    "\n",
    "    \n",
    "    \n",
    "    #Computes the \"logical and\" of elements across dimensions of a tensor.\n",
    "    finished = tf.reduce_all(elements_finished) # -> boolean scalar\n",
    "    #Return either fn1() or fn2() based on the boolean predicate pred.\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    \n",
    "    #set previous to current\n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "\n",
    "    return (elements_finished, \n",
    "            input,\n",
    "            state,\n",
    "            output,\n",
    "            loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:    # time == 0\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "\n",
    "#Creates an RNN specified by RNNCell cell and loop function loop_fn.\n",
    "#This function is a more primitive version of dynamic_rnn that provides more direct access to the \n",
    "#inputs each iteration. It also provides more control over when to start and finish reading the sequence, \n",
    "#and what to emit for the output.\n",
    "#ta = tensor array\n",
    "decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()\n",
    "#to convert output to human readable prediction\n",
    "#we will reshape output tensor\n",
    "\n",
    "#Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
    "#reduces dimensionality\n",
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "#flettened output tensor\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "#pass flattened tensor through decoder\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "#prediction vals\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))\n",
    "#final prediction\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cross entropy loss\n",
    "#one hot encode the target values so we don't rank just differentiate\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "#loss function\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "#train it \n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[6, 6, 6, 3, 9]\n",
      "[4, 9, 2, 3, 9, 3, 9]\n",
      "[6, 9, 2, 6]\n",
      "[8, 7, 5, 4, 3, 5, 3]\n",
      "[9, 9, 6, 7, 2, 3]\n",
      "[8, 3, 5]\n",
      "[6, 2, 4, 4]\n",
      "[4, 9, 6, 6]\n",
      "[4, 8, 4, 3, 6, 6, 4]\n",
      "[3, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "batch_size = 100\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)\n",
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] + [PAD] * 2 for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.024831999093294144\n",
      "  sample 1:\n",
      "    input     > [7 5 7 5 5 4 9 6]\n",
      "    predicted > [7 5 7 5 5 4 9 6 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 9 3 7 2 5 0 0]\n",
      "    predicted > [2 9 3 7 2 5 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 8 6 0 0 0 0 0]\n",
      "    predicted > [5 8 6 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.02052932418882847\n",
      "  sample 1:\n",
      "    input     > [9 2 8 5 5 5 7 0]\n",
      "    predicted > [9 2 8 5 5 5 7 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 6 9 7 2 8 0 0]\n",
      "    predicted > [3 6 9 7 2 8 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 6 7 8 9 6 9 0]\n",
      "    predicted > [3 6 7 8 9 6 9 1 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.018777921795845032\n",
      "  sample 1:\n",
      "    input     > [4 9 2 0 0 0 0 0]\n",
      "    predicted > [4 9 2 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 3 9 7 5 0 0 0]\n",
      "    predicted > [5 3 9 7 5 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 6 3 6 5 7 0 0]\n",
      "    predicted > [7 6 3 6 5 7 1 0 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.009434854611754417\n",
      "  sample 1:\n",
      "    input     > [4 6 5 7 3 0 0 0]\n",
      "    predicted > [4 6 5 7 3 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 2 8 5 7 8 0 0]\n",
      "    predicted > [2 2 8 5 7 8 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 5 8 8 6 8 7 0]\n",
      "    predicted > [5 5 8 8 6 8 7 1 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0099 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU9sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x219513c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
